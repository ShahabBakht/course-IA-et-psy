# SÃ©ance 3 : Classification et RÃ©gression

## Vue d'ensemble

Cette troisiÃ¨me sÃ©ance approfondit les concepts d'apprentissage automatique en explorant les deux grandes familles d'apprentissage supervisÃ© : la **classification** et la **rÃ©gression**. Nous verrons comment ces approches sont appliquÃ©es en psychologie et neurosciences, notamment pour les neuroprothÃ¨ses et la modÃ©lisation du cerveau. Nous comprendrons aussi les Ã©lÃ©ments clÃ©s de l'apprentissage automatique et comment les modÃ¨les sont entraÃ®nÃ©s.

---

## 1. Applications de l'apprentissage automatique en psychologie et neurosciences

### 1.1 NeuroprothÃ¨ses : DÃ©codage de la parole chez les patients paralysÃ©s

#### Le dÃ©fi

Un des dÃ©fis les plus importants et touchants de la neuroscience moderne est de redonner la parole aux personnes qui l'ont perdue Ã  cause d'un accident neurologique ou d'un dÃ©sordre neurologique, comme dans le cas de la paralysie.

```{admonition} VidÃ©o recommandÃ©e
:class: tip
Pour comprendre visuellement ce dÃ©fi et les progrÃ¨s rÃ©alisÃ©s, visionnez cette vidÃ©o :
[A high-performance neuroprosthesis for speech decoding and avatar control](https://www.youtube.com/watch?v=vL7yMn6kiMg)
```

#### Les rÃ©sultats actuels

**Performance actuelle :**
- Vitesse de dÃ©codage : **78 mots par minute**
- Conversation naturelle : **160 mots par minute**

```{important}
C'est un grand progrÃ¨s, mais nous avons encore une marge de progression significative. L'objectif est de se rapprocher le plus possible de la vitesse de conversation naturelle pour permettre une communication fluide.
```

#### Comment le modÃ¨le d'apprentissage automatique fonctionne

```{admonition} Architecture du systÃ¨me
:class: note

**EntrÃ©e â†’ ModÃ¨le â†’ Sortie**

- **EntrÃ©e :** DonnÃ©es cÃ©rÃ©brales (activitÃ© neuronale enregistrÃ©e)
- **ModÃ¨le :** SystÃ¨me d'apprentissage automatique entraÃ®nÃ©
- **Sortie :** Parole gÃ©nÃ©rÃ©e et texte correspondant
```

**Le modÃ¨le reÃ§oit les donnÃ©es du cerveau et gÃ©nÃ¨re ce qui nous intÃ©resse : la parole et les textes correspondants.**

#### Le dÃ©fi de la collecte de donnÃ©es

Une question cruciale se pose : **Comment collecter les donnÃ©es nÃ©cessaires pour entraÃ®ner le modÃ¨le alors que les patients ne peuvent pas parler ?**

```{admonition} Solution ingÃ©nieuse
:class: tip

**Technique de collecte de donnÃ©es :**

Avant d'entraÃ®ner le modÃ¨le, les chercheurs ont :

1. PrÃ©sentÃ© de nombreuses phrases et textes Ã  l'Ã©cran au patient
2. DemandÃ© au patient d'**essayer** de prononcer ces phrases
3. Pendant que le patient essayait (sans y arriver physiquement), enregistrÃ© l'activitÃ© cÃ©rÃ©brale
4. SupposÃ© que ces activitÃ©s correspondent aux phrases visÃ©es

**RÃ©sultat :** Phrases et activitÃ© cÃ©rÃ©brale - tout ce qui est nÃ©cessaire pour entraÃ®ner le modÃ¨le !
```

Cette technique fonctionne remarquablement bien, comme on peut le voir dans la vidÃ©o.

#### L'importance de la qualitÃ© des donnÃ©es

```{important}
**LeÃ§ons clÃ©s :**

1. **Le patient est le juge ultime** : Tant que le patient est satisfait des rÃ©sultats du modÃ¨le (le modÃ¨le dit ce que le patient veut dire), le modÃ¨le fonctionne. Si le patient voudrait dire quelque chose mais le modÃ¨le gÃ©nÃ¨re autre chose, c'est une erreur.

2. **La collecte de donnÃ©es est cruciale** : Trouver la meilleure faÃ§on de collecter les donnÃ©es nÃ©cessaires est une partie trÃ¨s importante de tous les projets d'apprentissage automatique.

3. **QualitÃ© = Performance** : La performance de votre modÃ¨le est largement influencÃ©e par la qualitÃ© de vos donnÃ©es.
```

### 1.2 NeuroprothÃ¨ses : Neuralink

#### Le projet Neuralink

Un autre exemple de neuroprothÃ¨se provient de Neuralink, l'entreprise dirigÃ©e par Elon Musk.

```{admonition} VidÃ©o dÃ©monstration
:class: tip
Regardez cette dÃ©monstration cÃ©lÃ¨bre :
[Pager, a nine year old Macaque, plays MindPong with his Neuralink](https://www.youtube.com/watch?v=rsCul1sp4hQ)

Certains d'entre vous l'ont peut-Ãªtre dÃ©jÃ  vue grÃ¢ce Ã  leur publicitÃ© intensive !
```

#### Le dÃ©fi

**Objectif :** ContrÃ´ler quelque chose avec l'activitÃ© cÃ©rÃ©brale, par exemple :
- Jouer au jeu de pong
- Bouger un objet sur l'Ã©cran
- **Uniquement en y pensant, sans interface manuelle**

#### Le rÃ´le de l'apprentissage automatique

```{admonition} Comment Ã§a fonctionne
:class: note

**Architecture similaire au dÃ©codage de la parole :**

**ActivitÃ© cÃ©rÃ©brale (entrÃ©e)** â†’ **ModÃ¨le d'apprentissage automatique** â†’ **Commandes de mouvement (sortie)**

Le modÃ¨le apprend Ã  traduire les intentions de mouvement (activitÃ© cÃ©rÃ©brale) en commandes concrÃ¨tes pour contrÃ´ler le curseur ou le jeu.
```

### 1.3 ModÃ©lisation du cerveau utilisant l'apprentissage automatique

#### Un nouveau paradigme de recherche

Au-delÃ  des applications cliniques, l'apprentissage automatique, et particuliÃ¨rement les **rÃ©seaux de neurones artificiels**, ouvre de nouvelles possibilitÃ©s pour la recherche fondamentale en neurosciences.

```{admonition} Lecture recommandÃ©e
:class: tip
Pour approfondir ce paradigme de recherche, consultez cet article de Nature Reviews Neuroscience :

[The neuroconnectionist research program](https://www.nature.com/articles/s41583-023-00705-w)
```

#### Le principe

**Question de recherche :** Est-il possible de dÃ©velopper un modÃ¨le capable de reproduire les activitÃ©s des neurones du cerveau en rÃ©ponse aux mÃªmes stimuli ?

**Exemple concret :** CrÃ©er un modÃ¨le qui peut imiter les activitÃ©s du systÃ¨me visuel en rÃ©ponse Ã  une sÃ©rie de stimuli visuels.

```{admonition} Architecture du modÃ¨le
:class: note

**Stimuli visuels (entrÃ©e)** â†’ **ModÃ¨le de neurones artificiels** â†’ **ActivitÃ©s neuronales prÃ©dites (sortie)**

Le modÃ¨le est entraÃ®nÃ© Ã  gÃ©nÃ©rer des activitÃ©s neuronales qui correspondent aux activitÃ©s rÃ©elles mesurÃ©es dans le cerveau.
```

**Pourquoi est-ce important ?**

Cette approche permet de :
1. **Tester des hypothÃ¨ses** sur le fonctionnement du cerveau
2. **Comprendre les reprÃ©sentations** dans diffÃ©rentes rÃ©gions cÃ©rÃ©brales
3. **PrÃ©dire** les rÃ©ponses neuronales Ã  de nouveaux stimuli
4. **DÃ©velopper des thÃ©ories computationnelles** de la cognition

---

## 2. Les Ã©lÃ©ments clÃ©s de l'apprentissage automatique

Maintenant que nous avons vu plusieurs exemples d'applications, explorons les composantes fondamentales qui constituent tout systÃ¨me d'apprentissage automatique.

### 2.1 Les donnÃ©es d'entraÃ®nement

```{important}
**DÃ©finition :**
Les donnÃ©es d'entraÃ®nement sont les **donnÃ©es d'entrÃ©e et de sortie Ã  partir desquelles le modÃ¨le apprend**.
```

**Dans tous nos exemples prÃ©cÃ©dents :**
- DÃ©codage de la parole : ActivitÃ© cÃ©rÃ©brale (entrÃ©e) + Parole correspondante (sortie)
- Neuralink : ActivitÃ© cÃ©rÃ©brale (entrÃ©e) + Mouvements dÃ©sirÃ©s (sortie)
- ModÃ©lisation du cerveau : Stimuli visuels (entrÃ©e) + ActivitÃ© neuronale (sortie)

```{admonition} Point critique
:class: warning
Sans donnÃ©es appropriÃ©es et de qualitÃ©, il est impossible d'entraÃ®ner un modÃ¨le performant. La collecte et la prÃ©paration des donnÃ©es reprÃ©sentent souvent la majeure partie du travail dans un projet d'apprentissage automatique.
```

### 2.2 Le modÃ¨le paramÃ©trique de l'apprentissage automatique

```{important}
**DÃ©finition :**
Le modÃ¨le est le **type de structure paramÃ©trique** qui va apprendre Ã  partir des donnÃ©es.
```

#### Questions importantes pour les chercheurs et dÃ©veloppeurs

**Choix du modÃ¨le :** Quel type de modÃ¨le est le plus appropriÃ© pour ce cas ?

**CaractÃ©ristiques des modÃ¨les :**
- Les modÃ¨les sont **paramÃ©trÃ©s** : ils ont des paramÃ¨tres ajustables
- Ces paramÃ¨tres permettent aux modÃ¨les de **s'adapter Ã  chaque tÃ¢che**
- Le processus d'apprentissage consiste Ã  ajuster ces paramÃ¨tres

```{admonition} Exemples de types de modÃ¨les
:class: note
- RÃ©gression linÃ©aire (modÃ¨le simple)
- RÃ©seaux de neurones artificiels (modÃ¨les complexes)
- Arbres de dÃ©cision
- Support Vector Machines (SVM)
- RÃ©seaux de neurones profonds (Deep Learning)
```

### 2.3 L'objectif de l'apprentissage (fonction objectif)

```{important}
**DÃ©finition :**
La fonction objectif est la **fonction mathÃ©matique qui dÃ©termine le but ou l'objectif de l'apprentissage**.
```

**RÃ´le :** Elle quantifie Ã  quel point le modÃ¨le performe bien sur les donnÃ©es d'entraÃ®nement.

```{admonition} Principe fondamental
:class: tip
Dans chaque application, on a besoin de **dÃ©finir trÃ¨s prÃ©cisÃ©ment** la fonction objectif du modÃ¨le. Cette fonction guide le processus d'apprentissage en indiquant ce que le modÃ¨le doit optimiser.
```

### 2.4 L'algorithme d'entraÃ®nement (algorithme d'optimisation)

```{important}
**DÃ©finition :**
L'algorithme d'entraÃ®nement est le **processus qui ajuste les paramÃ¨tres du modÃ¨le** pour amÃ©liorer sa performance selon la fonction objectif.
```

**Comment Ã§a fonctionne :**
1. L'algorithme Ã©value la performance actuelle du modÃ¨le (via la fonction objectif)
2. Il dÃ©termine comment modifier les paramÃ¨tres pour amÃ©liorer cette performance
3. Il ajuste les paramÃ¨tres en consÃ©quence
4. Le processus se rÃ©pÃ¨te jusqu'Ã  convergence

---

## 3. Types de donnÃ©es en apprentissage automatique

### 3.1 La diversitÃ© des types de donnÃ©es

L'une des forces de l'apprentissage automatique moderne est sa capacitÃ© Ã  traiter une grande variÃ©tÃ© de types de donnÃ©es.

```{admonition} Types de donnÃ©es courantes
:class: note

**DonnÃ©es structurÃ©es :**
- Images
- VidÃ©os
- Textes
- Audio/Sons
- SÃ©ries temporelles

**DonnÃ©es scientifiques spÃ©cialisÃ©es :**
- ActivitÃ©s cÃ©rÃ©brales (EEG, fMRI, enregistrements neuronaux)
- DonnÃ©es gÃ©nomiques
- DonnÃ©es mÃ©dicales (radiographies, IRM, etc.)

**DonnÃ©es multi-modales :**
- Images + Textes (captions)
- VidÃ©os + Sons
- Combinaisons diverses
```

```{important}
**Principe gÃ©nÃ©ral :**
Toutes les donnÃ©es possibles qui peuvent Ãªtre collectÃ©es de n'importe quelle maniÃ¨re peuvent potentiellement Ãªtre utilisÃ©es pour entraÃ®ner des modÃ¨les d'apprentissage automatique.
```

### 3.2 L'apprentissage multi-modal

On peut aussi utiliser un **mÃ©lange de types de donnÃ©es** comme entrÃ©es d'un modÃ¨le.

**Exemples :**
- Images avec des textes qui dÃ©crivent le contenu (captions)
- VidÃ©os et leurs bandes sonores
- Textes et mÃ©tadonnÃ©es temporelles

Cette approche multi-modale est de plus en plus utilisÃ©e dans les systÃ¨mes modernes d'IA.

---

## 4. L'apprentissage supervisÃ© : Classification

### 4.1 Introduction Ã  la classification

```{important}
**DÃ©finition :**
La classification est un type d'apprentissage supervisÃ© oÃ¹ le modÃ¨le doit **assigner chaque Ã©chantillon Ã  une catÃ©gorie prÃ©dÃ©finie**.
```

En fonction des sorties souhaitÃ©es du modÃ¨le, on peut avoir deux types diffÃ©rents d'apprentissage supervisÃ© : la **classification** et la **rÃ©gression**.

```{admonition} Point clÃ©
:class: note
Les **entrÃ©es** de ces deux types de problÃ¨mes ne sont pas diffÃ©rentes. Le mÃªme type d'entrÃ©es peut Ãªtre utilisÃ© pour la rÃ©gression et la classification. C'est le **type de sortie** qui dÃ©termine s'il s'agit de classification ou de rÃ©gression.
```

### 4.2 Exemple illustratif : Chiens et chats

ConsidÃ©rons des images de chiens et de chats comme donnÃ©es d'entrÃ©e.

**Pour la classification :**
On peut demander au modÃ¨le de dÃ©terminer s'il y a un chat ou un chien dans chaque image â†’ **Classification**

**Pour la rÃ©gression :**
On peut demander au modÃ¨le d'estimer l'Ã¢ge du chat ou du chien dans chaque image â†’ **RÃ©gression**

```{admonition} Question de rÃ©flexion
:class: tip
Qu'est-ce qu'on pourrait demander d'autre Ã  un modÃ¨le avec ces donnÃ©es d'entrÃ©e ?

Exemples possibles :
- Identifier la race de l'animal (classification multi-classe)
- Estimer le poids de l'animal (rÃ©gression)
- DÃ©terminer si l'animal est Ã  l'intÃ©rieur ou Ã  l'extÃ©rieur (classification)
```

### 4.3 Les sorties catÃ©gorielles

```{important}
**CaractÃ©ristique des sorties de classification :**

Les sorties catÃ©gorielles **classent les Ã©chantillons dans des catÃ©gories qualitatives**.

Il existe un **nombre fini** de catÃ©gories possibles pour chaque Ã©chantillon de donnÃ©es.
```

**ReprÃ©sentation numÃ©rique :**
Les sorties catÃ©gorielles sont reprÃ©sentÃ©es par des nombres entiers :
- 2 classes : 0, 1
- 3 classes : 0, 1, 2
- N classes : 0, 1, 2, ..., N-1

**Exemple binaire (chiens vs chats) :**
```
['chat', 'chat', 'chat', 'chien', 'chat', â€¦, 'chien', 'chat']
```
Devient :
```
[0, 0, 0, 1, 0, ..., 1, 0]
```

Le modÃ¨le doit apprendre Ã  gÃ©nÃ©rer le bon numÃ©ro pour chaque image en fonction de sa catÃ©gorie.

### 4.4 Exemple en neurosciences : Classification des directions de mouvement

#### Contexte expÃ©rimental

**Situation :** Un singe bouge sa main dans 7 directions diffÃ©rentes :
- Gauche
- Droite
- Haut
- Bas
- Haut-gauche
- Haut-droite
- Bas-gauche
- Bas-droite

**Mesure :** En mÃªme temps, on enregistre les activitÃ©s d'une rÃ©gion du cerveau, par exemple le **cortex moteur**.

**DonnÃ©es obtenues :** Mouvements de la main + ActivitÃ© cÃ©rÃ©brale correspondante

#### DÃ©finir le problÃ¨me de classification

```{admonition} Question
:class: tip
Comment peut-on dÃ©finir un problÃ¨me d'apprentissage automatique de classification Ã  partir de ces donnÃ©es ?
```

**RÃ©ponse :**

**EntrÃ©es :** ActivitÃ© cÃ©rÃ©brale (enregistrements neuronaux)
**Sorties :** Direction du mouvement (0-7, une pour chaque direction)
**Objectif :** Le modÃ¨le doit apprendre Ã  prÃ©dire la direction du mouvement Ã  partir de l'activitÃ© cÃ©rÃ©brale

```python
# ReprÃ©sentation des directions
directions = ['gauche', 'droite', 'haut', 'bas', 
              'haut-gauche', 'haut-droite', 'bas-gauche', 'bas-droite']
# EncodÃ©es comme : [0, 1, 2, 3, 4, 5, 6, 7]
```

#### Applications de ce modÃ¨le

```{admonition} UtilitÃ© du modÃ¨le entraÃ®nÃ©
:class: note

**1. Application clinique (neuroprothÃ¨se) :**
DÃ©terminer les mouvements possibles Ã  partir de l'activitÃ© du cerveau lorsque l'animal (ou un patient) **ne peut pas bouger sa main**, c'est-Ã -dire lorsqu'il est paralysÃ©.

**2. Recherche fondamentale (dÃ©codage du cerveau) :**
DÃ©terminer si ce type de classification est possible Ã  partir des activitÃ©s d'une rÃ©gion du cerveau. Est-ce que l'information nÃ©cessaire pour effectuer cette classification existe dans cette rÃ©gion ?

**RÃ©sultats connus :**
- âœ… Cortex moteur : Oui, la classification est possible (l'information est prÃ©sente)
- âŒ Cortex visuel : Non, l'information nÃ©cessaire n'est pas disponible dans cette rÃ©gion
```

Cette mÃ©thode scientifique s'appelle le **dÃ©codage du cerveau** (brain decoding).

### 4.5 Exemple en neurosciences : Classification d'orientation visuelle

#### Contexte expÃ©rimental

**Situation :** Une souris observe des stimuli visuels, en l'occurrence des **motifs en noir et blanc** (gratings) Ã  des angles diffÃ©rents :
- Horizontal (0Â°)
- Vertical (90Â°)
- Oblique Ã  45Â°
- Oblique Ã  135Â°
- Etc.

**Mesure :** En mÃªme temps, on enregistre les activitÃ©s d'une rÃ©gion du cerveau, par exemple le **cortex visuel**.

```{admonition} Question
:class: tip
Comment peut-on dÃ©finir un problÃ¨me d'apprentissage automatique de classification Ã  partir de ces donnÃ©es ?
```

#### La structure des donnÃ©es

**ReprÃ©sentation matricielle :**

La matrice enregistrÃ©e prÃ©sente toutes les donnÃ©es d'activitÃ©. Chaque Ã©lÃ©ment de cette matrice montre la **rÃ©ponse d'un neurone** Ã  un **stimulus spÃ©cifique** Ã  un **angle spÃ©cifique**.

```
         Neurone 1  Neurone 2  Neurone 3  ...  Neurone N
Essai 1     0.43      0.87       0.12    ...    0.65
Essai 2     0.51      0.79       0.21    ...    0.71
Essai 3     0.38      0.92       0.08    ...    0.58
...
```

**EntrÃ©es :** Toutes les donnÃ©es enregistrÃ©es sur les neurones (vecteur d'activitÃ© de tous les neurones)
**Sorties :** Angle correspondant (0Â°, 45Â°, 90Â°, 135Â°, etc.)

#### Application du modÃ¨le

```{important}
AprÃ¨s avoir formÃ© ce modÃ¨le, que pourrait-il faire ?

**RÃ©ponse :** C'est un exemple trÃ¨s simplifiÃ© de **"mind reading"** !

Ã€ partir de l'activitÃ© neuronale dans le cortex visuel, le modÃ¨le peut dÃ©terminer quel stimulus visuel (quelle orientation) l'animal est en train de regarder.
```

Cette technique a des implications profondes pour :
- Comprendre comment le cerveau encode l'information visuelle
- DÃ©velopper des interfaces cerveau-machine
- DÃ©coder les perceptions visuelles

### 4.6 La gÃ©omÃ©trie de la classification

#### Visualisation simplifiÃ©e avec deux neurones

ConsidÃ©rons une version simplifiÃ©e de l'exemple de classification des directions de mouvement :
- Seulement **deux directions** : gauche et droite
- Seulement **deux neurones** enregistrÃ©s

```{admonition} ReprÃ©sentation graphique
:class: note

**Diagramme de dispersion (scatter plot) :**

Axe X : ActivitÃ© du neurone 1
Axe Y : ActivitÃ© du neurone 2

- âšª Cercles : Mouvements vers la gauche
- ğŸ”º Triangles : Mouvements vers la droite

Chaque point reprÃ©sente les activitÃ©s des deux neurones pour l'une des deux directions.
```

**Objectif du modÃ¨le :** Apprendre Ã  dÃ©terminer si les activitÃ©s correspondent Ã  un mouvement vers la gauche ou vers la droite.

#### Classification linÃ©aire

```{important}
**Le modÃ¨le apprend une courbe qui sÃ©pare les Ã©chantillons des deux classes.**

Pour la **classification linÃ©aire**, cette courbe est une **ligne droite**.
```

**CaractÃ©ristiques :**
- De chaque cÃ´tÃ© de cette ligne, il n'y a que les Ã©chantillons d'une seule classe
- C'est appelÃ© "linÃ©aire" parce que la courbe est une ligne
- MathÃ©matiquement : une combinaison linÃ©aire des activitÃ©s des neurones dÃ©termine la classe

**Formule gÃ©nÃ©rale :**
```
y = wâ‚ Ã— xâ‚ + wâ‚‚ Ã— xâ‚‚ + b
```
OÃ¹ :
- xâ‚, xâ‚‚ : activitÃ©s des neurones 1 et 2
- wâ‚, wâ‚‚ : poids (paramÃ¨tres Ã  apprendre)
- b : biais (paramÃ¨tre Ã  apprendre)

#### Classification non linÃ©aire

```{important}
On peut avoir une **classification non linÃ©aire** avec une courbe qui n'est pas une ligne et qui est plus complexe.
```

**Avantages d'un modÃ¨le non linÃ©aire :**
- Plus complexe et plus adaptatif
- Plus de paramÃ¨tres Ã  ajuster
- Capable d'une classification plus complexe
- Peut sÃ©parer des classes qui ne sont pas linÃ©airement sÃ©parables

**InconvÃ©nients :**
- Risque de surapprentissage (overfitting)
- Plus difficile Ã  interprÃ©ter
- NÃ©cessite plus de donnÃ©es d'entraÃ®nement

---

## 5. L'apprentissage supervisÃ© : RÃ©gression

### 5.1 Introduction Ã  la rÃ©gression

```{important}
**DÃ©finition :**
La rÃ©gression est un type d'apprentissage supervisÃ© oÃ¹ le modÃ¨le doit **prÃ©dire une valeur numÃ©rique continue** pour chaque Ã©chantillon.
```

### 5.2 DiffÃ©rence entre classification et rÃ©gression

**Comme mentionnÃ© prÃ©cÃ©demment, la diffÃ©rence rÃ©side uniquement dans les sorties :**

**Classification :**
- Sorties catÃ©gorielles
- Nombre fini de possibilitÃ©s
- Exemples : chat/chien, directions de mouvement

**RÃ©gression :**
- Sorties numÃ©riques continues
- Peuvent prendre (thÃ©oriquement) toutes les valeurs possibles
- Exemples : Ã¢ge, vitesse, tempÃ©rature

```{admonition} Point clÃ©
:class: note
C'est diffÃ©rent de la classification oÃ¹ vous avez des sorties catÃ©gorielles avec des possibilitÃ©s limitÃ©es. En rÃ©gression, les sorties peuvent varier de maniÃ¨re continue dans une plage de valeurs.
```

### 5.3 Exemple en neurosciences : RÃ©gression de la vitesse de mouvement

#### Contexte expÃ©rimental

**Situation :** Notre singe bouge sa main dans diffÃ©rentes directions et Ã  diffÃ©rentes vitesses. En mÃªme temps, on enregistre les activitÃ©s du cerveau.

```{admonition} Question
:class: tip
Pouvez-vous dÃ©finir un problÃ¨me de rÃ©gression Ã  partir de ces donnÃ©es ?
```

#### DÃ©finition du problÃ¨me

**EntrÃ©es :** ActivitÃ© cÃ©rÃ©brale pendant les mouvements (mÃªmes donnÃ©es que pour la classification)
**Sorties :** Vitesse du mouvement (valeur numÃ©rique continue)

**DiffÃ©rence avec la classification :**
Au lieu de prÃ©dire la **direction** (catÃ©gorie), le modÃ¨le doit maintenant apprendre Ã  estimer la **vitesse** (valeur numÃ©rique).

```{important}
Comme la vitesse peut prendre n'importe quelle valeur (dans une plage), il s'agit d'une **rÃ©gression**.
```

**ReprÃ©sentation des sorties :**
```
[0.5, 1.2, 0.8, 2.1, 1.5, ..., 0.9, 1.7] (m/s)
```

#### Performance du modÃ¨le

Voici deux exemples de performances de modÃ¨les pour l'estimation de la vitesse Ã  partir de donnÃ©es cÃ©rÃ©brales, utilisant deux types de modÃ¨les :

**LSTM (Long Short-Term Memory)** et **SVR (Support Vector Regression)**

```{admonition} Visualisation de la performance
:class: note

Dans chaque diagramme :
- **Courbe noire** : Vitesse rÃ©elle (vÃ©ritable)
- **Courbes verte/rouge** : Sorties du modÃ¨le (prÃ©dictions)

**Ã‰valuation de la performance :**
- Plus les courbes sont similaires, plus le modÃ¨le est prÃ©cis
- Les deux courbes doivent Ãªtre aussi similaires que possible
- La diffÃ©rence entre les deux courbes doit Ãªtre minimale
```

Les rÃ©sultats montrent que les sorties des modÃ¨les sont trÃ¨s proches des valeurs rÃ©elles, dÃ©montrant l'efficacitÃ© de l'approche.

### 5.4 Exemple en neurosciences : PrÃ©diction d'activitÃ© neuronale

#### Contexte expÃ©rimental

**Situation :** Un modÃ¨le capable de gÃ©nÃ©rer des activitÃ©s du cerveau Ã  partir de stimuli visuels.

```{admonition} Questions de rÃ©flexion
:class: tip
- Comment peut-on faire cela ?
- Quelles sont les donnÃ©es d'entrÃ©e ?
- Quelles sont les sorties ?
- Comment peut-on collecter ces donnÃ©es ?
```

#### DÃ©finition du problÃ¨me

**EntrÃ©es :** Stimuli visuels (images)
**Sorties :** ActivitÃ©s neuronales prÃ©dites (valeurs numÃ©riques continues pour chaque neurone)

**Processus de collecte :**
1. PrÃ©senter des images Ã  un animal (ou humain)
2. Enregistrer simultanÃ©ment l'activitÃ© de neurones dans le cortex visuel
3. Obtenir des paires (image, activitÃ© neuronale)

**Application :**
Ce type de modÃ¨le permet de :
- PrÃ©dire comment le cerveau rÃ©pondra Ã  de nouveaux stimuli
- Tester des hypothÃ¨ses sur le traitement visuel
- Comprendre les reprÃ©sentations neuronales

### 5.5 La gÃ©omÃ©trie de la rÃ©gression

#### Visualisation avec un seul neurone

ConsidÃ©rons un exemple trÃ¨s simplifiÃ© basÃ© sur l'estimation de la vitesse Ã  partir de donnÃ©es du cerveau.

**HypothÃ¨se simplificatrice :** On a seulement **un neurone** enregistrÃ© pendant les mouvements du singe.

**Objectif :** EntraÃ®ner le modÃ¨le pour estimer la vitesse Ã  partir des activitÃ©s de ce seul neurone.

```{admonition} ReprÃ©sentation graphique
:class: note

**Diagramme de dispersion :**

Axe X : ActivitÃ© du neurone
Axe Y : Vitesse du mouvement

Les points montrent la relation entre l'activitÃ© neuronale et la vitesse observÃ©e.
```

#### Le modÃ¨le comme une courbe

```{important}
**Les courbes en rouge sont les modÃ¨les.**

Chaque courbe peut nous donner la vitesse pour chaque valeur d'activitÃ© de neurone.
```

**Deux types de modÃ¨les :**

1. **ModÃ¨le linÃ©aire :**
   - La courbe est une ligne droite
   - Formule : `vitesse = w Ã— activitÃ© + b`
   - Simple mais limitÃ©

2. **ModÃ¨le non linÃ©aire :**
   - La courbe est plus complexe qu'une ligne
   - Peut capturer des relations plus subtiles
   - Plus de paramÃ¨tres, plus adaptatif

```{important}
**Principe gÃ©nÃ©ral :**

Le modÃ¨le est une **courbe** qu'on peut entraÃ®ner (ou optimiser) pour faire quelque chose, estimer quelque chose, etc.

Les paramÃ¨tres du modÃ¨le dÃ©terminent la forme de cette courbe.
```

---

## 6. EntraÃ®nement du modÃ¨le : La fonction objectif

### 6.1 Introduction Ã  la fonction objectif

Maintenant que nous comprenons ce qu'est un modÃ¨le et comment il peut faire des prÃ©dictions (classification ou rÃ©gression), une question cruciale se pose :

```{admonition} Question centrale
:class: tip
Comment peut-on **quantifier** si un modÃ¨le fonctionne bien ou mal ?

Comment peut-on mesurer sa **performance** ?
```

**RÃ©ponse :** Nous avons besoin d'une **fonction objectif** (aussi appelÃ©e **fonction de perte** ou **loss function**).

### 6.2 Principe de la quantification de l'erreur

```{important}
Pour **quantifier la performance** d'un modÃ¨le, nous devons comparer :
- Les sorties **rÃ©elles** (les vraies valeurs)
- Les sorties **prÃ©dites** par le modÃ¨le

La **diffÃ©rence** entre ces deux valeurs constitue l'**erreur** du modÃ¨le.
```

### 6.3 Notation mathÃ©matique

**Convention de notation :**
- **y** : Sorties rÃ©elles (ground truth, vraies valeurs)
- **Å·** (y chapeau) : Sorties estimÃ©es/prÃ©dites par le modÃ¨le

**Pour diffÃ©rents Ã©chantillons :**
- yâ‚, yâ‚‚, yâ‚ƒ, ... : vraies valeurs pour les Ã©chantillons 1, 2, 3, ...
- Å·â‚, Å·â‚‚, Å·â‚ƒ, ... : valeurs prÃ©dites pour les Ã©chantillons 1, 2, 3, ...

### 6.4 Mean Squared Error (MSE) - Erreur quadratique moyenne

L'une des fonctions objectif les plus courantes pour la rÃ©gression est le **Mean Squared Error** (MSE).

```{important}
**Formule du MSE :**

MSE = (1/n) Ã— Î£(yáµ¢ - Å·áµ¢)Â²

OÃ¹ :
- n : nombre d'Ã©chantillons
- yáµ¢ : valeur rÃ©elle pour l'Ã©chantillon i
- Å·áµ¢ : valeur prÃ©dite pour l'Ã©chantillon i
- Î£ : somme sur tous les Ã©chantillons
```

**Calcul Ã©tape par Ã©tape :**

1. Pour chaque Ã©chantillon, prendre la sortie rÃ©elle (y) et la sortie estimÃ©e (Å·)
2. Calculer la diffÃ©rence : (y - Å·)
3. Calculer le carrÃ© de cette diffÃ©rence : (y - Å·)Â²
4. Faire la moyenne sur tous les Ã©chantillons

```{admonition} Pourquoi utiliser le carrÃ© ?
:class: note

**Raisons d'utiliser (y - Å·)Â² plutÃ´t que |y - Å·| :**

1. **PÃ©nalise davantage les grandes erreurs** : Une erreur de 10 donne 100, alors qu'une erreur de 2 donne seulement 4
2. **PropriÃ©tÃ©s mathÃ©matiques avantageuses** : Le carrÃ© est diffÃ©rentiable partout, ce qui facilite l'optimisation
3. **Convention standard** : Permet de comparer facilement diffÃ©rents modÃ¨les
```

**InterprÃ©tation :**
- MSE = 0 : ModÃ¨le parfait (prÃ©dictions exactes)
- MSE petit : Bon modÃ¨le
- MSE grand : ModÃ¨le imprÃ©cis

---

## 7. EntraÃ®nement du modÃ¨le : L'algorithme d'optimisation

### 7.1 Le rÃ´le de l'algorithme d'apprentissage

```{important}
Avec une quantification des erreurs (fonction objectif), maintenant on peut **entraÃ®ner le modÃ¨le**.

L'**algorithme d'apprentissage** (aka algorithme d'optimisation) utilise la sortie de la fonction objectif pour **changer, ajuster, ou optimiser les paramÃ¨tres du modÃ¨le** (W).
```

**Objectif :** L'algorithme d'apprentissage modifie les paramÃ¨tres de maniÃ¨re que :
- Le taux d'erreur du modÃ¨le soit **rÃ©duit**
- La performance du modÃ¨le **augmente, s'amÃ©liore** !

### 7.2 Une analogie : Le "Guessing Game"

Pour comprendre comment fonctionne l'algorithme d'apprentissage, considÃ©rons une analogie simple : le jeu de devinette.

#### Le jeu

**RÃ¨gles du jeu :**
1. Je choisis un chiffre (par exemple, 5014)
2. Vous devez le deviner
3. Ã€ chaque essai, je vous indique :
   - La **direction** de votre erreur (trop haut ou trop bas)
   - La **magnitude** de votre erreur (Ã  quelle distance vous Ãªtes)

#### ParallÃ¨le avec l'apprentissage automatique

```{admonition} Correspondances
:class: note

**Dans le jeu :**
- Votre estimation = Sortie du modÃ¨le
- Le vrai chiffre = Vraie valeur (y)
- Mon feedback = Fonction objectif
- Comment vous ajustez votre estimation = Algorithme d'apprentissage
```

#### Le processus itÃ©ratif

**ItÃ©ration 1 :**
- Vous : "300" (estimation initiale alÃ©atoire)
- Moi : "â†‘ Trop bas, erreur = 4714"

**ItÃ©ration 2 :**
- Vous : "2000" (ajustement basÃ© sur le feedback)
- Moi : "â†‘ Trop bas, erreur = 3014"

**ItÃ©ration 3 :**
- Vous : "5000" (ajustement)
- Moi : "â†‘ Trop bas, erreur = 14"

**ItÃ©ration 4 :**
- Vous : "5100" (ajustement)
- Moi : "â†“ Trop haut, erreur = 86"

**ItÃ©ration 5 :**
- Vous : "5050" (ajustement)
- Moi : "â†“ Trop haut, erreur = 36"

**ItÃ©ration 6 :**
- Vous : "5010" (ajustement)
- Moi : "â†“ Trop haut, erreur = 4"

```{important}
**Observation clÃ© :**

Ã€ chaque itÃ©ration, l'**erreur diminue** (en gÃ©nÃ©ral). C'est exactement ce qui se passe dans l'apprentissage automatique !
```

### 7.3 La courbe d'apprentissage

La **courbe d'apprentissage** montre l'Ã©volution de l'erreur au cours du processus d'entraÃ®nement.

```{admonition} CaractÃ©ristiques d'une bonne courbe d'apprentissage
:class: tip

**On veut que cette courbe montre la rÃ©duction des erreurs au cours de la pÃ©riode d'apprentissage.**

Axe X : Nombre d'itÃ©rations (epochs)
Axe Y : Erreur (fonction objectif)

Une bonne courbe d'apprentissage :
- â†˜ DÃ©croissante
- Converge vers une valeur faible
- Stable (sans oscillations excessives)
```

```{admonition} Signes de problÃ¨mes
:class: warning

Si l'erreur **ne diminue pas** au cours de l'apprentissage, cela indique un problÃ¨me :
- âŒ La quantification de l'erreur ne fonctionne pas
- âŒ L'algorithme d'apprentissage ne fonctionne pas
- âŒ Le modÃ¨le n'est pas adaptÃ© au problÃ¨me
- âŒ Les donnÃ©es ne sont pas appropriÃ©es
```

### 7.4 Ã‰lÃ©ments clÃ©s du processus d'apprentissage

En revisitant notre analogie du "Guessing Game", on identifie les Ã©lÃ©ments essentiels :

```{important}
**Composantes de l'apprentissage :**

1. **Initialisation** : On commence par une estimation alÃ©atoire
   - Sans feedback, on n'a aucune information
   - La premiÃ¨re estimation est par hasard

2. **Feedback** : Les erreurs sont le feedback nÃ©cessaire
   - Indiquent la direction et la magnitude du changement nÃ©cessaire
   - Essentiels pour guider l'ajustement

3. **Ajustement** : Modification basÃ©e sur le feedback
   - Les paramÃ¨tres sont modifiÃ©s pour rÃ©duire l'erreur
   - Processus itÃ©ratif et progressif
```

---

## 8. Les paramÃ¨tres du modÃ¨le : MÃ©taphore des boutons ajustables

### 8.1 Visualisation des paramÃ¨tres

```{important}
**MÃ©taphore utile :**

Le modÃ¨le est comme un **appareil avec beaucoup de boutons ajustables** (knobs).

Les **paramÃ¨tres du modÃ¨le** sont ces boutons ajustables.
```

**RÃ´le de l'algorithme d'apprentissage :**
L'algorithme doit changer les paramÃ¨tres selon les erreurs du modÃ¨le, permettant au modÃ¨le d'amÃ©liorer sa performance.

### 8.2 Le processus d'ajustement

```{admonition} Processus d'optimisation
:class: note

**Ã‰tape 1 : Initialisation**
- Tous les paramÃ¨tres sont ajustÃ©s Ã  des valeurs **alÃ©atoires**
- La premiÃ¨re sortie du modÃ¨le est donc alÃ©atoire

**Ã‰tape 2 : ItÃ©rations d'entraÃ®nement**
- Les paramÃ¨tres sont ajustÃ©s Ã  chaque itÃ©ration
- Objectif : **RÃ©duire ou minimiser la perte** (fonction objectif)

**Ã‰tape 3 : Convergence**
- Le processus continue jusqu'Ã  ce que l'erreur soit minimale
- Ou jusqu'Ã  ce qu'elle cesse de diminuer significativement
```

### 8.3 Exemple : RÃ©gression linÃ©aire

Pour comprendre concrÃ¨tement les paramÃ¨tres, considÃ©rons le modÃ¨le de rÃ©gression le plus simple : la **rÃ©gression linÃ©aire**.

#### ParamÃ©trisation du modÃ¨le

```{important}
**Formule du modÃ¨le linÃ©aire :**

y = W Â· x + b

OÃ¹ :
- **x** : donnÃ©es d'entrÃ©e
- **W** : poids (weights) - PARAMÃˆTRE Ã  apprendre
- **b** : biais (bias) - PARAMÃˆTRE Ã  apprendre
- **y** : sortie du modÃ¨le
```

**Il y a deux paramÃ¨tres ajustables :**
1. Les poids **W**
2. Les biais **b**

Ce sont ces paramÃ¨tres qui sont ajustÃ©s pendant l'entraÃ®nement.

#### Visualisation gÃ©omÃ©trique : Le rÃ´le des poids (W)

```{admonition} Impact du poids W
:class: note

Le modÃ¨le est reprÃ©sentÃ© par une **ligne** qui dÃ©termine la sortie selon les entrÃ©es.

**Les poids changent la pente de la ligne.**

Pendant l'entraÃ®nement, la pente est ajustÃ©e pour trouver la **meilleure pente** pour ces donnÃ©es.
```

**Exemple : Estimation de la vitesse de mouvement**

Axe X : ActivitÃ© neuronale
Axe Y : Vitesse prÃ©dite

DiffÃ©rentes valeurs de W donnent diffÃ©rentes pentes :
- W petit â†’ ligne presque horizontale
- W moyen â†’ pente modÃ©rÃ©e
- W grand â†’ ligne trÃ¨s inclinÃ©e

#### Visualisation gÃ©omÃ©trique : Le rÃ´le du biais (b)

```{admonition} Impact du biais b
:class: note

Le biais peut changer la **position** de la ligne (dÃ©calage vertical).

L'algorithme d'apprentissage l'ajuste pour obtenir le **meilleur ajustement** possible.
```

**Effet du biais :**
- b = 0 : la ligne passe par l'origine
- b > 0 : la ligne est dÃ©calÃ©e vers le haut
- b < 0 : la ligne est dÃ©calÃ©e vers le bas

```{important}
**Objectif de l'optimisation :**

Trouver les valeurs de W et b qui donnent la ligne qui **s'ajuste le mieux** aux donnÃ©es (minimise l'erreur quadratique moyenne).
```

### 8.4 Comment l'algorithme ajuste-t-il les paramÃ¨tres ?

```{admonition} AperÃ§u (dÃ©tails dans le cours d'apprentissage profond)
:class: note

**Question :** Comment l'algorithme d'apprentissage peut-il faire Ã§a ?

**RÃ©ponse courte :** C'est un sujet que nous explorerons en dÃ©tail dans le cours d'apprentissage profond.

**IdÃ©e gÃ©nÃ©rale :**
- L'algorithme calcule le **gradient** (dÃ©rivÃ©e) de la fonction objectif par rapport aux paramÃ¨tres
- Ce gradient indique dans quelle direction changer chaque paramÃ¨tre
- Les paramÃ¨tres sont ajustÃ©s dans cette direction
- Le processus est rÃ©pÃ©tÃ© itÃ©rativement
```

---

## 9. Concepts clÃ©s Ã  retenir

```{important}
**Points essentiels de cette sÃ©ance :**

1. **Applications en neurosciences** : L'apprentissage automatique permet des avancÃ©es majeures dans les neuroprothÃ¨ses (dÃ©codage de la parole, contrÃ´le par la pensÃ©e) et la modÃ©lisation du cerveau.

2. **Ã‰lÃ©ments clÃ©s de l'apprentissage automatique** :
   - DonnÃ©es d'entraÃ®nement (entrÃ©es + sorties)
   - ModÃ¨le paramÃ©trique
   - Fonction objectif
   - Algorithme d'optimisation

3. **Classification vs RÃ©gression** :
   - **Classification** : sorties catÃ©gorielles (nombre fini de classes)
   - **RÃ©gression** : sorties numÃ©riques continues
   - La diffÃ©rence rÃ©side dans le type de sortie, pas dans les entrÃ©es

4. **GÃ©omÃ©trie de l'apprentissage** :
   - **Classification** : trouver une courbe qui sÃ©pare les classes
   - **RÃ©gression** : trouver une courbe qui prÃ©dit les valeurs
   - ModÃ¨les linÃ©aires vs non linÃ©aires

5. **EntraÃ®nement du modÃ¨le** :
   - **Fonction objectif** : quantifie l'erreur (ex: MSE)
   - **Algorithme d'optimisation** : ajuste les paramÃ¨tres pour rÃ©duire l'erreur
   - **Processus itÃ©ratif** : amÃ©lioration progressive par feedback

6. **ParamÃ¨tres du modÃ¨le** : boutons ajustables qui dÃ©terminent le comportement du modÃ¨le (ex: poids W et biais b dans la rÃ©gression linÃ©aire)

7. **Importance de la qualitÃ© des donnÃ©es** : la performance du modÃ¨le dÃ©pend crucialement de la qualitÃ© et de la pertinence des donnÃ©es d'entraÃ®nement
```

---

## 10. Questions de rÃ©flexion

```{admonition} Pour approfondir votre comprÃ©hension
:class: tip

1. **Applications cliniques** : Quelles autres applications neuroprothÃ©tiques pourrait-on dÃ©velopper avec l'apprentissage automatique ? Pensez Ã  diffÃ©rentes fonctions cÃ©rÃ©brales qui pourraient Ãªtre restaurÃ©es.

2. **Ã‰thique et neuroprothÃ¨ses** : Quelles sont les implications Ã©thiques du dÃ©codage de l'activitÃ© cÃ©rÃ©brale ? OÃ¹ tracer la ligne entre aide mÃ©dicale et invasion de la vie privÃ©e mentale ?

3. **Classification vs rÃ©gression** : Donnez trois exemples de problÃ¨mes de classification et trois exemples de problÃ¨mes de rÃ©gression en psychologie.

4. **QualitÃ© des donnÃ©es** : Pourquoi la qualitÃ© des donnÃ©es est-elle si cruciale ? Quels problÃ¨mes peuvent survenir avec des donnÃ©es biaisÃ©es ou de mauvaise qualitÃ© ?

5. **ModÃ¨les linÃ©aires vs non linÃ©aires** : Dans quelles situations un modÃ¨le linÃ©aire serait-il suffisant ? Quand aurait-on absolument besoin d'un modÃ¨le non linÃ©aire ?

6. **Fonction objectif** : Pourquoi utilise-t-on l'erreur quadratique (carrÃ©e) plutÃ´t que l'erreur absolue ? Quels sont les avantages et inconvÃ©nients ?

7. **DÃ©codage du cerveau** : Comment le dÃ©codage du cerveau peut-il aider Ã  comprendre comment diffÃ©rentes rÃ©gions cÃ©rÃ©brales traitent l'information ?
```

---

## 11. Ressources complÃ©mentaires

### Articles scientifiques

```{admonition} Lectures recommandÃ©es
:class: tip

**Sur les neuroprothÃ¨ses et le dÃ©codage de la parole :**
- Metzger et al. (2023). "A high-performance neuroprosthesis for speech decoding and avatar control." *Nature*. [doi: 10.1038/s41586-023-06443-4](https://doi.org/10.1038/s41586-023-06443-4)

**Sur la modÃ©lisation du cerveau avec l'apprentissage automatique :**
- Richards et al. (2023). "The neuroconnectionist research program." *Nature Reviews Neuroscience*. [Article disponible](https://www.nature.com/articles/s41583-023-00705-w)
```

### VidÃ©os

```{admonition} DÃ©monstrations visuelles
:class: note

**NeuroprothÃ¨se de dÃ©codage de la parole :**
[VidÃ©o dÃ©monstration](https://www.youtube.com/watch?v=vL7yMn6kiMg)

**Neuralink - ContrÃ´le par la pensÃ©e :**
[Pager joue Ã  MindPong](https://www.youtube.com/watch?v=rsCul1sp4hQ)
```

### Concepts pour la prochaine sÃ©ance

Dans la prochaine sÃ©ance, nous approfondirons :
- Les diffÃ©rents types d'algorithmes d'apprentissage automatique
- L'apprentissage non supervisÃ©
- Les rÃ©seaux de neurones et l'apprentissage profond
- Comment Ã©viter le surapprentissage (overfitting)

---

**Fin de la SÃ©ance 3**
