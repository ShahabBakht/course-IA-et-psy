{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Exercices Pratiques - R√©gression et Classification\n",
    "\n",
    "## PSY3913/6913 - IA, Psychologie et Neuroscience Cognitive\n",
    "\n",
    "Ce notebook contient des exercices progressifs pour mettre en pratique les concepts de r√©gression et classification lin√©aires.\n",
    "\n",
    "**Instructions:**\n",
    "- Lisez attentivement chaque exercice\n",
    "- Compl√©tez le code dans les cellules pr√©vues\n",
    "- Ex√©cutez et testez votre code\n",
    "- R√©pondez aux questions de r√©flexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.datasets import make_circles\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 1 : R√©gression avec features polynomiales\n",
    "\n",
    "### Contexte\n",
    "Dans cet exercice, vous allez d√©couvrir comment am√©liorer un mod√®le lin√©aire en ajoutant des features polynomiales pour capturer des relations non-lin√©aires.\n",
    "\n",
    "### Donn√©es\n",
    "Nous allons cr√©er des donn√©es suivant une relation **quadratique** : $y = 0.5x^2 + 2x + 1 + \\text{bruit}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer les donn√©es\n",
    "np.random.seed(42)\n",
    "X_ex1 = np.random.rand(100, 1) * 10 - 5  # Valeurs entre -5 et 5\n",
    "y_ex1 = 0.5 * X_ex1**2 + 2 * X_ex1 + 1 + np.random.randn(100, 1) * 5\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_ex1, y_ex1, alpha=0.6)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Donn√©es avec relation non-lin√©aire')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Observation: Les donn√©es suivent clairement une courbe, pas une ligne!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 1.1 : Mod√®le lin√©aire simple\n",
    "\n",
    "Commencez par entra√Æner un mod√®le de r√©gression lin√©aire simple sur ces donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er et entra√Æner un mod√®le de r√©gression lin√©aire\n",
    "model_linear = LinearRegression()\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: Faire des pr√©dictions\n",
    "y_pred_linear = # Votre code ici\n",
    "\n",
    "# TODO: Calculer R¬≤ et MSE\n",
    "r2_linear = # Votre code ici\n",
    "mse_linear = # Votre code ici\n",
    "\n",
    "print(f\"üìà Performance du mod√®le lin√©aire:\")\n",
    "print(f\"   R¬≤ = {r2_linear:.4f}\")\n",
    "print(f\"   MSE = {mse_linear:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "X_plot = np.linspace(-5, 5, 100).reshape(-1, 1)\n",
    "y_plot_linear = model_linear.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_ex1, y_ex1, alpha=0.6, label='Donn√©es')\n",
    "plt.plot(X_plot, y_plot_linear, 'r-', linewidth=2, label='R√©gression lin√©aire')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('R√©gression lin√©aire sur donn√©es non-lin√©aires')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 1.2 : Mod√®le avec features polynomiales\n",
    "\n",
    "Maintenant, utilisez `PolynomialFeatures` pour cr√©er des features polynomiales de degr√© 2, puis entra√Ænez un nouveau mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er des features polynomiales (degr√© 2)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = # Votre code ici\n",
    "\n",
    "print(f\"Forme originale: {X_ex1.shape}\")\n",
    "print(f\"Forme avec features polynomiales: {X_poly.shape}\")\n",
    "print(f\"\\nFeatures cr√©√©es: x, x¬≤\")\n",
    "\n",
    "# TODO: Entra√Æner le mod√®le sur les features polynomiales\n",
    "model_poly = LinearRegression()\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: Faire des pr√©dictions\n",
    "y_pred_poly = # Votre code ici\n",
    "\n",
    "# TODO: Calculer R¬≤ et MSE\n",
    "r2_poly = # Votre code ici\n",
    "mse_poly = # Votre code ici\n",
    "\n",
    "print(f\"\\nüìà Performance du mod√®le polynomial:\")\n",
    "print(f\"   R¬≤ = {r2_poly:.4f}\")\n",
    "print(f\"   MSE = {mse_poly:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "X_plot_poly = poly.transform(X_plot)\n",
    "y_plot_poly = model_poly.predict(X_plot_poly)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_ex1, y_ex1, alpha=0.6, label='Donn√©es')\n",
    "plt.plot(X_plot, y_plot_linear, 'r-', linewidth=2, label='Lin√©aire', alpha=0.5)\n",
    "plt.plot(X_plot, y_plot_poly, 'g-', linewidth=2, label='Polynomial (degr√© 2)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Comparaison: Lin√©aire vs Polynomial')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Comparaison:\")\n",
    "print(f\"   Am√©lioration du R¬≤: {r2_poly - r2_linear:.4f}\")\n",
    "print(f\"   R√©duction du MSE: {mse_linear - mse_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question de r√©flexion 1\n",
    "\n",
    "**Q1:** Pourquoi le mod√®le polynomial performe-t-il mieux ?\n",
    "\n",
    "*Votre r√©ponse:*\n",
    "\n",
    "**Q2:** Que se passerait-il si vous utilisiez un degr√© polynomial trop √©lev√© (par exemple, degr√© 10) ?\n",
    "\n",
    "*Votre r√©ponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 2 : Classification avec donn√©es d√©s√©quilibr√©es\n",
    "\n",
    "### Contexte\n",
    "En neurosciences, il est fr√©quent d'avoir des classes d√©s√©quilibr√©es (par exemple, beaucoup plus d'essais dans une direction que dans une autre). Dans cet exercice, vous allez apprendre √† g√©rer ce probl√®me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des donn√©es d√©s√©quilibr√©es\n",
    "np.random.seed(42)\n",
    "\n",
    "# Classe 0: 80 √©chantillons\n",
    "X_class0 = np.random.randn(80, 2) + np.array([-2, -2])\n",
    "y_class0 = np.zeros(80)\n",
    "\n",
    "# Classe 1: 20 √©chantillons (minoritaire)\n",
    "X_class1 = np.random.randn(20, 2) + np.array([2, 2])\n",
    "y_class1 = np.ones(20)\n",
    "\n",
    "# Combiner\n",
    "X_ex2 = np.vstack([X_class0, X_class1])\n",
    "y_ex2 = np.hstack([y_class0, y_class1])\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_ex2[y_ex2==0, 0], X_ex2[y_ex2==0, 1], \n",
    "           c='blue', label=f'Classe 0 (n={np.sum(y_ex2==0)})', alpha=0.6, edgecolors='k')\n",
    "plt.scatter(X_ex2[y_ex2==1, 0], X_ex2[y_ex2==1, 1], \n",
    "           c='red', label=f'Classe 1 (n={np.sum(y_ex2==1)})', alpha=0.6, edgecolors='k')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Dataset avec classes d√©s√©quilibr√©es (80/20)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚öñÔ∏è D√©s√©quilibre:\")\n",
    "print(f\"   Classe 0: {np.sum(y_ex2==0)} √©chantillons ({np.sum(y_ex2==0)/len(y_ex2)*100:.1f}%)\")\n",
    "print(f\"   Classe 1: {np.sum(y_ex2==1)} √©chantillons ({np.sum(y_ex2==1)/len(y_ex2)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 2.1 : Mod√®le sans pond√©ration\n",
    "\n",
    "Entra√Ænez un mod√®le de r√©gression logistique standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des donn√©es\n",
    "X_train_ex2, X_test_ex2, y_train_ex2, y_test_ex2 = train_test_split(\n",
    "    X_ex2, y_ex2, test_size=0.3, random_state=42, stratify=y_ex2\n",
    ")\n",
    "\n",
    "# TODO: Entra√Æner le mod√®le sans pond√©ration\n",
    "model_unweighted = LogisticRegression(random_state=42)\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: Pr√©dictions et √©valuation\n",
    "y_pred_unweighted = # Votre code ici\n",
    "accuracy_unweighted = # Votre code ici\n",
    "\n",
    "print(f\"üìà Accuracy (sans pond√©ration): {accuracy_unweighted:.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_unweighted = confusion_matrix(y_test_ex2, y_pred_unweighted)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_unweighted, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Classe 0', 'Classe 1'],\n",
    "           yticklabels=['Classe 0', 'Classe 1'])\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('Vraie classe')\n",
    "plt.title('Matrice de confusion (sans pond√©ration)')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° Question: Le mod√®le performe-t-il bien sur la classe minoritaire (classe 1)?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 2.2 : Mod√®le avec pond√©ration\n",
    "\n",
    "Utilisez `class_weight='balanced'` pour donner plus d'importance √† la classe minoritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner le mod√®le avec pond√©ration √©quilibr√©e\n",
    "model_weighted = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: Pr√©dictions et √©valuation\n",
    "y_pred_weighted = # Votre code ici\n",
    "accuracy_weighted = # Votre code ici\n",
    "\n",
    "print(f\"üìà Accuracy (avec pond√©ration): {accuracy_weighted:.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_weighted = confusion_matrix(y_test_ex2, y_pred_weighted)\n",
    "\n",
    "# Comparaison c√¥te √† c√¥te\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "sns.heatmap(cm_unweighted, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "           xticklabels=['Classe 0', 'Classe 1'],\n",
    "           yticklabels=['Classe 0', 'Classe 1'])\n",
    "axes[0].set_title('Sans pond√©ration')\n",
    "axes[0].set_xlabel('Pr√©diction')\n",
    "axes[0].set_ylabel('Vraie classe')\n",
    "\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "           xticklabels=['Classe 0', 'Classe 1'],\n",
    "           yticklabels=['Classe 0', 'Classe 1'])\n",
    "axes[1].set_title('Avec pond√©ration')\n",
    "axes[1].set_xlabel('Pr√©diction')\n",
    "axes[1].set_ylabel('Vraie classe')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Comparaison:\")\n",
    "print(f\"   Vrais positifs (classe 1):\")\n",
    "print(f\"      Sans pond√©ration: {cm_unweighted[1,1]}\")\n",
    "print(f\"      Avec pond√©ration: {cm_weighted[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question de r√©flexion 2\n",
    "\n",
    "**Q1:** Quelle diff√©rence observez-vous dans les matrices de confusion ?\n",
    "\n",
    "*Votre r√©ponse:*\n",
    "\n",
    "**Q2:** Dans quel contexte clinique ou de recherche serait-il crucial d'utiliser class_weight='balanced' ?\n",
    "\n",
    "*Votre r√©ponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 3 : Limites des mod√®les lin√©aires\n",
    "\n",
    "### Contexte\n",
    "Les mod√®les lin√©aires ont des limites importantes. Dans cet exercice, vous allez voir un cas o√π la classification lin√©aire √©choue compl√®tement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des donn√©es en cercles (non lin√©airement s√©parables)\n",
    "X_circles, y_circles = make_circles(n_samples=300, noise=0.1, factor=0.5, random_state=42)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_circles[y_circles==0, 0], X_circles[y_circles==0, 1],\n",
    "           c='blue', label='Classe 0 (cercle ext√©rieur)', alpha=0.6, edgecolors='k')\n",
    "plt.scatter(X_circles[y_circles==1, 0], X_circles[y_circles==1, 1],\n",
    "           c='red', label='Classe 1 (cercle int√©rieur)', alpha=0.6, edgecolors='k')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Dataset avec classes non lin√©airement s√©parables')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Observation: Aucune ligne droite ne peut s√©parer ces deux classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 3.1 : Essayer la r√©gression logistique standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des donn√©es\n",
    "X_train_circles, X_test_circles, y_train_circles, y_test_circles = train_test_split(\n",
    "    X_circles, y_circles, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Entra√Æner un mod√®le de r√©gression logistique\n",
    "model_circles = LogisticRegression(random_state=42)\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: √âvaluation\n",
    "y_pred_circles = # Votre code ici\n",
    "accuracy_circles = # Votre code ici\n",
    "\n",
    "print(f\"üìà Accuracy: {accuracy_circles:.4f}\")\n",
    "print(f\"\\nüí° Cette accuracy est proche de 50% (hasard) - le mod√®le lin√©aire √©choue!\")\n",
    "\n",
    "# Visualiser la fronti√®re de d√©cision\n",
    "def plot_decision_boundary_circles(model, X, y):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, levels=1, colors=['blue', 'red'])\n",
    "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', label='Classe 0',\n",
    "               alpha=0.7, edgecolors='k', s=50)\n",
    "    plt.scatter(X[y==1, 0], X[y==1, 1], c='red', label='Classe 1',\n",
    "               alpha=0.7, edgecolors='k', s=50)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('Fronti√®re de d√©cision (r√©gression logistique lin√©aire)')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary_circles(model_circles, X_circles, y_circles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 3.2 : Am√©liorer avec des features non-lin√©aires\n",
    "\n",
    "Cr√©ez des features non-lin√©aires pour am√©liorer la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er des features polynomiales (essayez degr√© 2)\n",
    "poly_circles = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_circles_poly = # Votre code ici\n",
    "\n",
    "print(f\"Forme originale: {X_circles.shape}\")\n",
    "print(f\"Forme avec features polynomiales: {X_circles_poly.shape}\")\n",
    "\n",
    "# Division\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(\n",
    "    X_circles_poly, y_circles, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# TODO: Entra√Æner le mod√®le sur les features polynomiales\n",
    "model_circles_poly = LogisticRegression(random_state=42, max_iter=1000)\n",
    "# Votre code ici\n",
    "\n",
    "\n",
    "# TODO: √âvaluation\n",
    "y_pred_circles_poly = # Votre code ici\n",
    "accuracy_circles_poly = # Votre code ici\n",
    "\n",
    "print(f\"\\nüìà Performance:\")\n",
    "print(f\"   Lin√©aire: {accuracy_circles:.4f}\")\n",
    "print(f\"   Polynomial: {accuracy_circles_poly:.4f}\")\n",
    "print(f\"\\n‚ú® Am√©lioration: {(accuracy_circles_poly - accuracy_circles)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question de r√©flexion 3\n",
    "\n",
    "**Q1:** Pourquoi le mod√®le polynomial performe-t-il mieux ?\n",
    "\n",
    "*Votre r√©ponse:*\n",
    "\n",
    "**Q2:** Quelles sont les alternatives aux features polynomiales pour g√©rer des donn√©es non lin√©airement s√©parables ?\n",
    "\n",
    "*Votre r√©ponse (indices: r√©seaux de neurones, SVM avec kernel, etc.):*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 4 : Projet int√©gratif - Pr√©diction de performance cognitive\n",
    "\n",
    "### Contexte\n",
    "Vous avez des donn√©es simul√©es d'une √©tude en neurosciences o√π on mesure :\n",
    "- Activit√© de plusieurs r√©gions c√©r√©brales (features)\n",
    "- Score de performance √† une t√¢che cognitive (cible)\n",
    "\n",
    "**Votre mission :** Construire le meilleur mod√®le pr√©dictif possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer des donn√©es simul√©es\n",
    "np.random.seed(123)\n",
    "\n",
    "n_subjects = 150\n",
    "n_regions = 8  # 8 r√©gions c√©r√©brales\n",
    "\n",
    "# Activit√© c√©r√©brale (features)\n",
    "X_cog = np.random.randn(n_subjects, n_regions) * 10 + 50\n",
    "\n",
    "# Score de performance (relation complexe)\n",
    "# Certaines r√©gions contribuent plus que d'autres\n",
    "weights_true = np.array([2.0, 1.5, 0.5, -0.8, 1.0, 0.3, 1.8, -0.5])\n",
    "y_cog = X_cog.dot(weights_true) + np.random.randn(n_subjects) * 15 + 200\n",
    "\n",
    "# Normaliser le score entre 0 et 100\n",
    "y_cog = (y_cog - y_cog.min()) / (y_cog.max() - y_cog.min()) * 100\n",
    "\n",
    "print(f\"üìä Dataset:\")\n",
    "print(f\"   Nombre de sujets: {n_subjects}\")\n",
    "print(f\"   Nombre de r√©gions c√©r√©brales: {n_regions}\")\n",
    "print(f\"   Score moyen: {y_cog.mean():.2f}\")\n",
    "print(f\"   Score std: {y_cog.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 4.1 : Exploration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er des visualisations pour explorer les donn√©es\n",
    "# 1. Distribution du score de performance\n",
    "# 2. Corr√©lation entre chaque r√©gion et le score\n",
    "# Votre code ici\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 4.2 : Standardisation des donn√©es\n",
    "\n",
    "En pratique, il est souvent important de standardiser les features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Diviser les donn√©es en train/test\n",
    "X_train_cog, X_test_cog, y_train_cog, y_test_cog = # Votre code ici\n",
    "\n",
    "# TODO: Standardiser les features (moyenne=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train_cog_scaled = # Votre code ici\n",
    "X_test_cog_scaled = # Votre code ici\n",
    "\n",
    "print(f\"üìä Standardisation:\")\n",
    "print(f\"   Avant - moyenne: {X_train_cog.mean(axis=0)[:3]}...\")\n",
    "print(f\"   Apr√®s - moyenne: {X_train_cog_scaled.mean(axis=0)[:3]}...\")\n",
    "print(f\"   Apr√®s - std: {X_train_cog_scaled.std(axis=0)[:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 4.3 : Entra√Ænement et √©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entra√Æner un mod√®le de r√©gression lin√©aire\n",
    "model_cog = # Votre code ici\n",
    "\n",
    "# TODO: Pr√©dictions et √©valuation\n",
    "y_train_pred_cog = # Votre code ici\n",
    "y_test_pred_cog = # Votre code ici\n",
    "\n",
    "# TODO: Calculer les m√©triques\n",
    "train_r2_cog = # Votre code ici\n",
    "test_r2_cog = # Votre code ici\n",
    "train_rmse_cog = # Votre code ici  (RMSE = sqrt(MSE))\n",
    "test_rmse_cog = # Votre code ici\n",
    "\n",
    "print(f\"üìà Performance:\")\n",
    "print(f\"   Train - R¬≤: {train_r2_cog:.4f}, RMSE: {train_rmse_cog:.2f}\")\n",
    "print(f\"   Test  - R¬≤: {test_r2_cog:.4f}, RMSE: {test_rmse_cog:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T√¢che 4.4 : Visualisations et interpr√©tation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cr√©er les visualisations suivantes\n",
    "# 1. Scatter plot: pr√©dictions vs vraies valeurs\n",
    "# 2. R√©sidus vs pr√©dictions\n",
    "# 3. Importance des r√©gions c√©r√©brales (poids du mod√®le)\n",
    "# Votre code ici\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question de r√©flexion 4\n",
    "\n",
    "**Q1:** Quelles r√©gions c√©r√©brales sont les plus importantes pour pr√©dire la performance ?\n",
    "\n",
    "*Votre r√©ponse:*\n",
    "\n",
    "**Q2:** Le mod√®le est-il en surapprentissage (overfitting) ou sous-apprentissage (underfitting) ? Justifiez.\n",
    "\n",
    "*Votre r√©ponse:*\n",
    "\n",
    "**Q3:** Comment pourriez-vous am√©liorer ce mod√®le ?\n",
    "\n",
    "*Votre r√©ponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice Bonus : Impl√©mentation compl√®te from scratch\n",
    "\n",
    "### D√©fi\n",
    "Impl√©mentez une classe compl√®te de r√©gression lin√©aire qui supporte :\n",
    "1. √âquations normales\n",
    "2. Descente de gradient\n",
    "3. R√©gularisation Ridge (L2)\n",
    "\n",
    "```python\n",
    "class AdvancedLinearRegression:\n",
    "    def __init__(self, method='normal', alpha=0.01, lambda_reg=0.0, n_iterations=1000):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        method : str, 'normal' ou 'gradient'\n",
    "        alpha : float, learning rate pour gradient descent\n",
    "        lambda_reg : float, coefficient de r√©gularisation\n",
    "        n_iterations : int, nombre d'it√©rations pour gradient descent\n",
    "        \"\"\"\n",
    "        # Votre impl√©mentation ici\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Votre impl√©mentation ici\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Votre impl√©mentation ici\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre impl√©mentation compl√®te ici\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "F√©licitations d'avoir compl√©t√© ces exercices ! üéâ\n",
    "\n",
    "### Ce que vous avez appris:\n",
    "\n",
    "‚úÖ Comment am√©liorer les mod√®les lin√©aires avec des features polynomiales\n",
    "\n",
    "‚úÖ G√©rer les classes d√©s√©quilibr√©es avec la pond√©ration\n",
    "\n",
    "‚úÖ Reconna√Ætre les limites des mod√®les lin√©aires\n",
    "\n",
    "‚úÖ Standardiser les donn√©es pour de meilleures performances\n",
    "\n",
    "‚úÖ Construire un pipeline complet d'analyse de donn√©es\n",
    "\n",
    "‚úÖ Interpr√©ter les r√©sultats et identifier les features importantes\n",
    "\n",
    "### Prochaines √©tapes:\n",
    "\n",
    "- Explorez des datasets r√©els (UCI Machine Learning Repository, Kaggle)\n",
    "- Apprenez les r√©seaux de neurones pour g√©rer des relations plus complexes\n",
    "- Pratiquez avec vos propres donn√©es de recherche en psychologie/neurosciences\n",
    "\n",
    "**Bon apprentissage ! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}